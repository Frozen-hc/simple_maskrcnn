{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "ann_file = \"../annotations/instances_val2017.json\"\n",
    "coco = COCO(ann_file) #生成coco对象"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco.imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'license': 4, 'file_name': '000000397133.jpg', 'coco_url': 'http://images.cocodataset.org/val2017/000000397133.jpg', 'height': 427, 'width': 640, 'date_captured': '2013-11-14 17:02:52', 'flickr_url': 'http://farm7.staticflickr.com/6116/6255196340_da26cf2c9e_z.jpg', 'id': 397133}\n"
     ]
    }
   ],
   "source": [
    "# api: coco.imgs\n",
    "ids = [str(k) for k in coco.imgs]\n",
    "# print(len(ids))\n",
    "print(coco.imgs[int(ids[0])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'supercategory': 'person', 'id': 1, 'name': 'person'}, 2: {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'}, 3: {'supercategory': 'vehicle', 'id': 3, 'name': 'car'}, 4: {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'}, 5: {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'}, 6: {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'}, 7: {'supercategory': 'vehicle', 'id': 7, 'name': 'train'}, 8: {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'}, 9: {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'}, 10: {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'}, 11: {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'}, 13: {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'}, 14: {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'}, 15: {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'}, 16: {'supercategory': 'animal', 'id': 16, 'name': 'bird'}, 17: {'supercategory': 'animal', 'id': 17, 'name': 'cat'}, 18: {'supercategory': 'animal', 'id': 18, 'name': 'dog'}, 19: {'supercategory': 'animal', 'id': 19, 'name': 'horse'}, 20: {'supercategory': 'animal', 'id': 20, 'name': 'sheep'}, 21: {'supercategory': 'animal', 'id': 21, 'name': 'cow'}, 22: {'supercategory': 'animal', 'id': 22, 'name': 'elephant'}, 23: {'supercategory': 'animal', 'id': 23, 'name': 'bear'}, 24: {'supercategory': 'animal', 'id': 24, 'name': 'zebra'}, 25: {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'}, 27: {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'}, 28: {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'}, 31: {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}, 32: {'supercategory': 'accessory', 'id': 32, 'name': 'tie'}, 33: {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'}, 34: {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'}, 35: {'supercategory': 'sports', 'id': 35, 'name': 'skis'}, 36: {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'}, 37: {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'}, 38: {'supercategory': 'sports', 'id': 38, 'name': 'kite'}, 39: {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'}, 40: {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'}, 41: {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'}, 42: {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'}, 43: {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'}, 44: {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'}, 46: {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'}, 47: {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'}, 48: {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'}, 49: {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'}, 50: {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'}, 51: {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'}, 52: {'supercategory': 'food', 'id': 52, 'name': 'banana'}, 53: {'supercategory': 'food', 'id': 53, 'name': 'apple'}, 54: {'supercategory': 'food', 'id': 54, 'name': 'sandwich'}, 55: {'supercategory': 'food', 'id': 55, 'name': 'orange'}, 56: {'supercategory': 'food', 'id': 56, 'name': 'broccoli'}, 57: {'supercategory': 'food', 'id': 57, 'name': 'carrot'}, 58: {'supercategory': 'food', 'id': 58, 'name': 'hot dog'}, 59: {'supercategory': 'food', 'id': 59, 'name': 'pizza'}, 60: {'supercategory': 'food', 'id': 60, 'name': 'donut'}, 61: {'supercategory': 'food', 'id': 61, 'name': 'cake'}, 62: {'supercategory': 'furniture', 'id': 62, 'name': 'chair'}, 63: {'supercategory': 'furniture', 'id': 63, 'name': 'couch'}, 64: {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'}, 65: {'supercategory': 'furniture', 'id': 65, 'name': 'bed'}, 67: {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'}, 70: {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'}, 72: {'supercategory': 'electronic', 'id': 72, 'name': 'tv'}, 73: {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'}, 74: {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'}, 75: {'supercategory': 'electronic', 'id': 75, 'name': 'remote'}, 76: {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'}, 77: {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'}, 78: {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'}, 79: {'supercategory': 'appliance', 'id': 79, 'name': 'oven'}, 80: {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'}, 81: {'supercategory': 'appliance', 'id': 81, 'name': 'sink'}, 82: {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'}, 84: {'supercategory': 'indoor', 'id': 84, 'name': 'book'}, 85: {'supercategory': 'indoor', 'id': 85, 'name': 'clock'}, 86: {'supercategory': 'indoor', 'id': 86, 'name': 'vase'}, 87: {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'}, 88: {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'}, 89: {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'}, 90: {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}}\n"
     ]
    }
   ],
   "source": [
    "classes = {k: v[\"name\"] for k, v in coco.cats.items()} # 类别\n",
    "print(coco.cats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.utils.data.SubSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.9065, -0.9241, -0.9772]), tensor(0.1027))\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TensorDataset(Dataset):\n",
    "    \"\"\"\n",
    "    TensorDataset继承Dataset, 重载了__init__(), __getitem__(), __len__()\n",
    "    实现将一组Tensor数据对封装成Tensor数据集\n",
    "    能够通过index得到数据集的数据，能够通过len，得到数据集大小\n",
    "    \"\"\"\n",
    "    def __init__(self, data_tensor, target_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "# 生成数据\n",
    "data_tensor = torch.randn(4, 3)\n",
    "target_tensor = torch.rand(4)\n",
    "\n",
    "# 将数据封装成Dataset\n",
    "tensor_dataset = TensorDataset(data_tensor, target_tensor)\n",
    "\n",
    "# 可使用索引调用数据\n",
    "print(tensor_dataset[1])\n",
    "# 输出：(tensor([-1.0351, -0.1004,  0.9168]), tensor(0.4977))\n",
    "\n",
    "# 获取数据集大小\n",
    "print(len(tensor_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.1445,  1.4546, -0.8368]), tensor(0.5118))\n",
      "(tensor([ 0.0369,  0.1086, -0.0431]), tensor(0.8527))\n",
      "(tensor([0.5010, 0.1304, 0.3635]), tensor(0.5879))\n",
      "(tensor([-1.6325, -0.7381, -1.4347]), tensor(0.4056))\n",
      "[1, 2, 3, 0]\n",
      "(tensor([ 0.0369,  0.1086, -0.0431]), tensor(0.8527))\n",
      "(tensor([0.5010, 0.1304, 0.3635]), tensor(0.5879))\n",
      "(tensor([-1.6325, -0.7381, -1.4347]), tensor(0.4056))\n",
      "(tensor([-0.1445,  1.4546, -0.8368]), tensor(0.5118))\n"
     ]
    }
   ],
   "source": [
    "for i in tensor_dataset:\n",
    "    print(i)\n",
    "indices =torch.randperm(len(tensor_dataset)).tolist()\n",
    "d_train = torch.utils.data.Subset(tensor_dataset, indices)\n",
    "print(indices)\n",
    "for i in d_train:\n",
    "    print(i)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# del_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================model_state_dict===================================\n",
      "['backbone.fpn.inner_blocks.3.weight', 'backbone.fpn.inner_blocks.3.bias']\n",
      "===============================================pretrained_msd=================================\n",
      "===============================================pretrained_msd after del=================================\n"
     ]
    }
   ],
   "source": [
    "model_urls = {\n",
    "            'maskrcnn_resnet50_fpn_coco':\n",
    "                'https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth',\n",
    "        }\n",
    "model_state_dict = torch.load('pytorch_mask_rcnn\\checkpoints\\maskrcnn_resnet50_fpn_coco.pth')\n",
    "print('=====================================model_state_dict===================================')\n",
    "print(list(model_state_dict.keys())[271:273])\n",
    "\n",
    "pretrained_msd = list(model_state_dict.values()) #msd: model state dict\n",
    "print('===============================================pretrained_msd=================================')\n",
    "# print(pretrained_msd[265])\n",
    "del_list = [i for i in range(265, 271)] + [i for i in range(273, 279)]\n",
    "for i, del_idx in enumerate(del_list):\n",
    "    pretrained_msd.pop(del_idx - i)\n",
    "print('===============================================pretrained_msd after del=================================')\n",
    "# print(len(pretrained_msd))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet50 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "FrozenBatchNorm2d(64, eps=1e-05)\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "body = torchvision.models.resnet.__dict__['resnet50'](\n",
    "            pretrained=True, norm_layer=torchvision.ops.misc.FrozenBatchNorm2d)\n",
    "# for name, parameter in body.named_children():\n",
    "#     print(name)\n",
    "# body = torch.nn.ModuleDict(d for i, d in enumerate(body.named_children()) if i < 8)\n",
    "# for model in body.values():\n",
    "#     print(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3121,  0.7346,  0.8934,  0.4210,  0.9530, -0.6478])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((2,3)).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = torch.tensor([1,2,3])\n",
    "ratios = torch.tensor([1,2,0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frozen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0fcceb56ad45502efe27603fc48219b9563384b44c82bfa135beb84ebccd890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
